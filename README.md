# E-Commerce Data Pipeline Project

**Student:** Divya Eeli  
**Roll Number:** 22A91A61E8  
**Submission Date:** December 27, 2025

## ğŸ“‹ Project Overview

End-to-End ETL Pipeline for E-Commerce Analytics Platform - A production-ready data engineering solution demonstrating:
- Three-tier database architecture (staging, production, warehouse)
- Automated ETL/ELT workflows
- Data quality assurance and monitoring
- Business Intelligence dashboards
- Docker containerization and CI/CD

## ğŸ—ï¸ Architecture

### Database Design
- **Staging Schema**: Raw data ingestion with minimal constraints
- **Production Schema**: Normalized (3NF) with full constraints and indexes
- **Warehouse Schema**: Star schema with SCD Type 2 for dimensional modeling

### Tech Stack
- **Data Generation**: Python (Faker library)
- **Database**: PostgreSQL 14
- **ETL**: Python (Pandas, SQLAlchemy)
- **Orchestration**: Apache Airflow / Cron
- **BI Tool**: Tableau Public / Power BI Desktop
- **Containerization**: Docker & Docker Compose
- **CI/CD**: GitHub Actions
- **Testing**: Pytest (>80% coverage)

## ğŸ“Š Data Specifications

- **Customers**: 1,000 records
- **Products**: 500 records
- **Transactions**: 10,000 records
- **Transaction Items**: 15,000-25,000 records
- **Referential Integrity**: 100% (zero orphan records)

## ğŸš€ Quick Start

### Prerequisites
```bash
Python 3.8+
PostgreSQL 12+
Docker & Docker Compose
Git
```

### Installation

1. Clone the repository
```bash
git clone https://github.com/22A91A61E8/ecommerce-data-pipeline-22A91A61E8.git
cd ecommerce-data-pipeline-22A91A61E8
```

2. Set up environment
```bash
cp .env.example .env
# Edit .env with your database credentials
```

3. Install dependencies
```bash
pip install -r requirements.txt
```

4. Run with Docker (Recommended)
```bash
docker-compose up -d
```

5. Or run locally
```bash
bash setup.sh
python scripts/main.py
```

## ğŸ“ Project Structure

```
ecommerce-data-pipeline/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Generated CSV files
â”‚   â”œâ”€â”€ staging/             # Intermediate processed data
â”‚   â””â”€â”€ processed/           # Final clean data & reports
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ data_generation/     # Data generation scripts
â”‚   â”œâ”€â”€ ingestion/           # Data ingestion to staging
â”‚   â”œâ”€â”€ transformation/      # ETL transformations
â”‚   â””â”€â”€ quality_checks/      # Data quality validation
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ ddl/                 # Schema creation scripts
â”‚   â”œâ”€â”€ dml/                 # Data manipulation
â”‚   â””â”€â”€ queries/             # Analytical queries
â”œâ”€â”€ dashboards/              # BI dashboards & screenshots
â”œâ”€â”€ docker/                  # Docker configuration
â”œâ”€â”€ tests/                   # Unit & integration tests
â”œâ”€â”€ docs/                    # Documentation
â”œâ”€â”€ config/                  # Configuration files
â”œâ”€â”€ .github/workflows/       # CI/CD pipelines
â””â”€â”€ logs/                    # Application logs
```

## ğŸ”„ Pipeline Workflow

1. **Data Generation**: Generate realistic e-commerce data
2. **Staging Load**: Bulk load raw data to staging schema
3. **Data Quality**: Validate completeness, uniqueness, consistency
4. **Transformation**: Cleanse and apply business rules
5. **Production Load**: Load to normalized production schema
6. **Warehouse Load**: Build dimensional model with SCD Type 2
7. **Analytics**: Create aggregates and run analytical queries
8. **Dashboard**: Visualize insights in BI tool

## ğŸ¯ Key Features

- âœ… 100% referential integrity
- âœ… Idempotent pipeline execution
- âœ… Comprehensive data quality framework
- âœ… SCD Type 2 implementation
- âœ… Automated testing (>80% coverage)
- âœ… Docker containerization
- âœ… CI/CD pipeline
- âœ… Detailed documentation

## ğŸ“ˆ Dashboard

[Link to Tableau Public Dashboard / Power BI Screenshots]

- **Page 1**: Executive KPIs & Sales Overview
- **Page 2**: Product Performance Analysis
- **Page 3**: Customer Segmentation
- **Page 4**: Geographic Distribution

## ğŸ§ª Testing

Run tests with coverage:
```bash
pytest --cov=scripts --cov-report=html
```

## ğŸ“ Documentation

- [Architecture Documentation](docs/architecture.md)
- [Dashboard Guide](docs/dashboard_guide.md)
- [API Documentation](docs/api_documentation.md)
- [SUBMISSION.md](SUBMISSION.md)

## ğŸ” Configuration

Key configuration in `config/config.yaml`:
- Database connection parameters
- Data generation settings
- Pipeline batch sizes
- Logging levels

## ğŸ“Š Project Statistics

- **Lines of Code**: TBD
- **Test Coverage**: >80%
- **Data Records Processed**: 30,000+
- **Execution Time**: ~5 minutes

## ğŸ¤ Contributing

This is a student project for academic evaluation.

## ğŸ“„ License

MIT License

## ğŸ“§ Contact

Divya Eeli - 22A91A61E8

---
**Note**: This project is part of the Global Placement Program - Data Engineering Track
